# Interview Note

**Company**: b  
**Position**: b  
**Date**: 2025-06-02  
**Round**: 1  
**Category**: 多问题  

## 🧾 Structured Summary

[其他] 什么是RDD？

- **Definition**: 弹性分布式数据集（Resilient Distributed Dataset），是Spark中的基本数据结构，代表一个不可变、可分区、可并行操作的数据集合。
- **Example**: 可以从HDFS、HBase、本地文件系统等数据源创建RDD，并对其进行转换和动作操作。
- **Answer**: 在面试中可以回答RDD是Spark中的基本数据结构，具有容错性和并行性，支持各种操作和转换。

---

[其他] 在PySpark中如何创建RDD？

- **Definition**: 可以通过`sc.parallelize()`方法从一个已有的集合（如列表）创建RDD，也可以通过`sc.textFile()`方法从外部数据源（如文本文件）创建RDD。
- **Example**: `rdd = sc.parallelize([1, 2, 3, 4, 5])` 或 `rdd = sc.textFile("hdfs://path/to/file")`
- **Answer**: 在面试中可以回答可以使用`sc.parallelize()`方法从集合创建RDD，也可以使用`sc.textFile()`方法从外部数据源创建RDD。

---

## 📝 Raw Interview Note

rdd
pyspark